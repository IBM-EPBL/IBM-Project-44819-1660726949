{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1KItZMk4kLU"
      },
      "outputs": [],
      "source": [
        "import os, types\n",
        "import pandas as pd\n",
        "from botocore.client import Config\n",
        "import ibm_boto3\n",
        "\n",
        "def __iter__(self): return 0\n",
        "\n",
        "# @hidden_cell\n",
        "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
        "# You might want to remove those credentials before you share the notebook.\n",
        "cos_client = ibm_boto3.client(service_name='s3',\n",
        "    ibm_api_key_id='QVsKoX6yNRLn8Qv_RWlO4N-PlH8ddMdZyPPjLiIW1oz6',\n",
        "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
        "    config=Config(signature_version='oauth'),\n",
        "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
        "\n",
        "bucket = 'imageclassification-donotdelete-pr-ncc5wgfie3fmsd'\n",
        "object_key = 'Dataset.zip'\n",
        "\n",
        "streaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "import zipfile\n",
        "unzip=zipfile.ZipFile(BytesIO(streaming_body_2.read()),'r')\n",
        "file_paths=unzip.namelist()\n",
        "for path in file_paths:\n",
        "    unzip.extract(path)"
      ],
      "metadata": {
        "id": "uLhUp2lJ65eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "IRhJJWy065vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "filenames=os.listdir('/home/wsuser/work/Dataset/train_set')"
      ],
      "metadata": {
        "id": "CkE255uv65yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install libgl1-mesa-dev\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n"
      ],
      "metadata": {
        "id": "JMtkZXBv651D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the parameters/arguments for ImageDataGenerator class"
      ],
      "metadata": {
        "id": "AMLHbJsF7WcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train=ImageDataGenerator(rescale=1./255,\n",
        "                                 shear_range=0.2,\n",
        "                                 rotation_range=180,\n",
        "                                 zoom_range=0.2,\n",
        "                                 horizontal_flip=True)\n",
        "train = ImageDataGenerator(rescale=1/255)\n",
        "test = ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "LMrU3aYc653x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying ImageDataGenerator functionality to trainset"
      ],
      "metadata": {
        "id": "BmVUUSmR7gcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train.flow_from_directory(\"/home/wsuser/work/Dataset/train_set\",\n",
        "                                          target_size=(64,64),\n",
        "                                          batch_size = 32,\n",
        "                                          class_mode = 'binary' )"
      ],
      "metadata": {
        "id": "h92333xF656R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying ImageDataGenerator functionality to testset"
      ],
      "metadata": {
        "id": "H0WkNA6R7rsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test.flow_from_directory(\"/home/wsuser/work/Dataset/test_set\",\n",
        "                                          target_size=(64,64),\n",
        "                                          batch_size = 32,\n",
        "                                          class_mode = 'binary' )"
      ],
      "metadata": {
        "id": "P6Rhody3659d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.class_indices"
      ],
      "metadata": {
        "id": "aBb--4PA73Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'forest': 0, 'with fire': 1}\n",
        "Import model building libraries"
      ],
      "metadata": {
        "id": "XSwBPHLl8MtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to define linear initialisation import sequential\n",
        "from keras.models import Sequential\n",
        "#to add layer import Dense\n",
        "from keras.layers import Dense\n",
        "#to create convolution kernel import convolution2D\n",
        "from keras.layers import Convolution2D\n",
        "#import Maxpooling layer\n",
        "from keras.layers import MaxPooling2D\n",
        "#import flatten layer\n",
        "from keras.layers import Flatten\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "nykSeLA973S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing the model"
      ],
      "metadata": {
        "id": "ahaZ8OMq8ajk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model =Sequential()"
      ],
      "metadata": {
        "id": "nPHUQDCX73V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add CNN Layer"
      ],
      "metadata": {
        "id": "8jYLmKB38h0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation='relu'))\n",
        "#add maxpooling layers\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#add faltten layer\n",
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "A2rdNCmq73YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Hidden Layer"
      ],
      "metadata": {
        "id": "hwNYWY9R8rLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add hidden layers\n",
        "model.add(Dense(150,activation='relu'))\n",
        "#add output layer\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "EZtUYY8H73a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure the learning process"
      ],
      "metadata": {
        "id": "IUD0r9X88x20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = \"adam\",\n",
        "              metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "60fnwImj73dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "hv_VKrz686Xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(x_train,steps_per_epoch=14,epochs=5,validation_data=x_test,validation_steps=20)"
      ],
      "metadata": {
        "id": "JUWuu0YH73f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save The Model"
      ],
      "metadata": {
        "id": "VLcT9LZu9BKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/home/wsuser/work/archive(1)/forest1.h5\")"
      ],
      "metadata": {
        "id": "JVXjrcz573iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)\n",
        "predictions = np.round(predictions)"
      ],
      "metadata": {
        "id": "dvVZW13i73lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "BOv1KhO573oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictions))"
      ],
      "metadata": {
        "id": "C9tVg6PU73rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import load_model from keras.model\n",
        "from keras.models import load_model\n",
        "#import image class from keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "#import numpy\n",
        "import numpy as np\n",
        "#import cv2"
      ],
      "metadata": {
        "id": "kYWbSZA573uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the saved model\n",
        "model = load_model(\"/home/wsuser/work/archive(1)/forest1.h5\")"
      ],
      "metadata": {
        "id": "kvLTIeGy9XCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictImage(filename):\n",
        "  img1 = image.load_img(filename,target_size=(64,64))\n",
        "  Y = image.img_to_array(img1)\n",
        "  X = np.expand_dims(Y,axis=0)\n",
        "  val = model.predict(X)\n",
        "  print(val)\n",
        "  if val == 1:\n",
        "    print(\" fire\")\n",
        "  elif val == 0:\n",
        "      print(\"no fire\")"
      ],
      "metadata": {
        "id": "OJqObDYn9XFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictImage(\"/home/wsuser/work/Dataset/test_set/with fire/19464620_401.jpg\")"
      ],
      "metadata": {
        "id": "nMUQtcyU9XIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenCV For Video Processing"
      ],
      "metadata": {
        "id": "WvB6P01b9jd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install twilio\n",
        "Collecting twilio\n",
        "  Downloading twilio-7.15.2-py2.py3-none-any.whl (1.4 MB)\n",
        "     |████████████████████████████████| 1.4 MB 16.7 MB/s eta 0:00:01\n",
        "Requirement already satisfied: requests>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from twilio) (2.26.0)\n",
        "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from twilio) (2.4.0)\n",
        "Requirement already satisfied: pytz in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from twilio) (2021.3)\n",
        "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests>=2.0.0->twilio) (3.3)\n",
        "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests>=2.0.0->twilio) (2022.9.24)\n",
        "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests>=2.0.0->twilio) (1.26.7)\n",
        "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests>=2.0.0->twilio) (2.0.4)\n",
        "Installing collected packages: twilio\n",
        "Successfully installed twilio-7.15.2\n",
        "Note: you may need to restart the kernel to use updated packages."
      ],
      "metadata": {
        "id": "fSWBlydO9XKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install playsound\n",
        "Collecting playsound\n",
        "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
        "Building wheels for collected packages: playsound\n",
        "  Building wheel for playsound (setup.py) ... done\n",
        "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7037 sha256=7a14e5d7212967bf1952d7558b36640342f7d1b687b5aa9dc5b0e950f2e73b31\n",
        "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/ba/39/54/c8f7ff9a88a644d3c58b4dec802d90b79a2e0fb2a6b884bf82\n",
        "Successfully built playsound\n",
        "Installing collected packages: playsound\n",
        "Successfully installed playsound-1.3.0\n",
        "Note: you may need to restart the kernel to use updated packages."
      ],
      "metadata": {
        "id": "zK2xRDDF9XN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import opencv librariy\n",
        "#import cv2\n",
        "#import numpy\n",
        "import numpy as np\n",
        "#import image function from keras\n",
        "from keras.preprocessing import image\n",
        "#import load_model from keras\n",
        "from keras.models import load_model\n",
        "#import client from twilio API\n",
        "from twilio.rest import Client\n",
        "#imort playsound package\n",
        "from playsound import playsound"
      ],
      "metadata": {
        "id": "TFGPH5gI9XQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the saved model\n",
        "model = load_model(r'/home/wsuser/work/archive(1)/forest1.h5')\n",
        "#define the features\n",
        "name = ['forest','with forest']"
      ],
      "metadata": {
        "id": "i3dG4BDx9XSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating An Account In Twilio Service"
      ],
      "metadata": {
        "id": "7N-OaK9B93eU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "account_sid='ACfb4e6d0e7b0d25def63044919f1b96e3'\n",
        "auth_token='f9ae4fc4a617a527da8672e97eefb2d8'\n",
        "client=Client(account_sid,auth_token)\n",
        "message=client.messages \\\n",
        ".create(\n",
        "      body='Forest Fire is detected, stay alert',\n",
        "      from_='+1 302 248 4366',\n",
        "      to='+91 99400 12164'\n",
        ")\n",
        "print(message.sid)"
      ],
      "metadata": {
        "id": "__3NRSj99XVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sending Alert Message"
      ],
      "metadata": {
        "id": "4DVVvWD29-Rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pygobject\n",
        "Collecting pygobject\n",
        "  Downloading PyGObject-3.42.2.tar.gz (719 kB)\n",
        "     |████████████████████████████████| 719 kB 9.3 MB/s eta 0:00:01\n",
        "  Installing build dependencies ... error"
      ],
      "metadata": {
        "id": "JckQroJ69XX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def message(val):\n",
        "  if val==1:\n",
        "    from twilio.rest import Client\n",
        "    print('Forest fire')\n",
        "    account_sid='ACfb4e6d0e7b0d25def63044919f1b96e3'\n",
        "    auth_token='f9ae4fc4a617a527da8672e97eefb2d8'\n",
        "    client=Client(account_sid,auth_token)\n",
        "    message=client.messages \\\n",
        "     .create(\n",
        "        body='forest fire is detected, stay alert',\n",
        "        #use twilio free number\n",
        "        from_='+1 302 248 4366',\n",
        "        #to number\n",
        "        to='+91 99400 12164')\n",
        "    print(message.sid)\n",
        "    print(\"Fire detected\")\n",
        "    print(\"SMS Sent!\")\n",
        "  elif val==0:\n",
        "    print('No Fire')"
      ],
      "metadata": {
        "id": "vOGvrY399XZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#import load model from keras.model\n",
        "from keras.models import load_model\n",
        "#import image from keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img1 = image.load_img('/home/wsuser/work/Dataset/test_set/with fire/Wild_fires.jpg',target_size=(64,64))\n",
        "Y = image.img_to_array(img1)\n",
        "x = np.expand_dims(Y,axis=0)\n",
        "val = model.predict(x)\n",
        "plt.imshow(img1)\n",
        "plt.show()\n",
        "message(val)"
      ],
      "metadata": {
        "id": "XXXmGJVX9Xc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img2 = image.load_img('/home/wsuser/work/Dataset/test_set/forest/1200px_Mountainarea.jpg',target_size=(64,64))\n",
        "Y = image.img_to_array(img2)\n",
        "x = np.expand_dims(Y,axis=0)\n",
        "val = model.predict(x)\n",
        "plt.imshow(img2)\n",
        "plt.show()\n",
        "message(val)\n"
      ],
      "metadata": {
        "id": "CkHFz8EW9XfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ibm_watson_machine_learning import APIClient\n",
        "wml_credentials={\"url\":\"https://us-south.ml.cloud.ibm.com\",\"apikey\":\"TFXoHzN3M76f8UM68mdo_MshGtF2Dk1H56fJ67oDagbV\"}\n",
        "client=APIClient(wml_credentials)"
      ],
      "metadata": {
        "id": "LM0UPhWz9Xhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def guid_from_space_name(client,space_name):\n",
        "    space=client.spaces.get_details()\n",
        "    return(next(item for item in space['resources']if item['entity'][\"name\"]==space_name)['metadata']['id'])"
      ],
      "metadata": {
        "id": "stE6E2La9XkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "space_uid=guid_from_space_name(client,'imageclassification')\n",
        "print(\"Space UID= \"+space_uid)"
      ],
      "metadata": {
        "id": "r55odWiP9XnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.set.default_space(space_uid)\n",
        "'SUCCESS'"
      ],
      "metadata": {
        "id": "HpwdI_0H-bcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.software_specifications.list()"
      ],
      "metadata": {
        "id": "_68BRp1e-bey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "software_spec_uid=client.software_specifications.get_uid_by_name(\"tensorflow_1.15-py3.6\")\n",
        "software_spec_uid"
      ],
      "metadata": {
        "id": "-l5nzLxE-bh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras"
      ],
      "metadata": {
        "id": "fqolGidb-bkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yeGXVG_f-bm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KUin3R1X-bpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fSGsgsBb-bsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NJh6wjVp-bvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XZ7Nfuto-b4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b01frhQ3-b7f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}